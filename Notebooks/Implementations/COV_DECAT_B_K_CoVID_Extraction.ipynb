{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, importlib\n",
    "import geohash\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on processing status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_folder = \"/home/wb411133/data/Projects/CoVID\"\n",
    "all_folders = []\n",
    "all_zips = []\n",
    "for thing in os.listdir(covid_folder):\n",
    "    path = os.path.join(covid_folder, thing)\n",
    "    if os.path.isdir(path):\n",
    "        all_folders.append(path)\n",
    "    elif thing[-4:] == \".zip\":\n",
    "        all_zips.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "bad_files = []\n",
    "for folder in all_folders:\n",
    "    shps = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f[-4:] == \".shp\":\n",
    "                shps.append(f)\n",
    "            if f[:3] == \"ADM\":\n",
    "                bad_files.append(os.path.join(root, f))\n",
    "    outputs[os.path.basename(folder)] = shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for DevSeed\n",
    "\n",
    "Need to ensure data follow strict data structure:\n",
    "\n",
    "1. All files delivered as GeoJSON\n",
    "2. Ensure all files have geohash\n",
    "3. Deliver preliminary zonal results as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from infrasap import covid_data_extraction as cov\n",
    "importlib.reload(cov)\n",
    "    \n",
    "dhs_definitions = '/home/public/Data/PROJECTS/CoVID/DHS/column_definitions.csv'\n",
    "dhs = pd.read_csv(dhs_definitions)\n",
    "column_defs = {}\n",
    "for idx, row in dhs.iterrows():\n",
    "    column_defs['%s_SUM' % row['Column_name']] = 'Total %s' % row['Definition']\n",
    "    column_defs['%s_MEAN' % row['Column_name']] = 'Mean density %s' % row['Definition']    \n",
    "\n",
    "class covid_result(object):\n",
    "    def __init__(self, country, files, cur_folder, dhs_column_defs):\n",
    "        self.dhs_column_defs = dhs_column_defs\n",
    "        self.iso3 = country\n",
    "        self.files = files\n",
    "        self.cur_folder = cur_folder\n",
    "        self.LC_cols = ['LC_%s' % x for x in [11,14,20,30,40,50,60,70,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230]]\n",
    "        self.final_folder = os.path.join(cur_folder, \"FINAL_GEOMS\")\n",
    "        self.final_stats_folder = os.path.join(cur_folder, \"FINAL_STATS\")\n",
    "        self.bad_cols = ['R10_SUM',\"P1_SUM\",\"P2_SUM\",\"Shape_Leng\",\"Shape_Area\"]\n",
    "        self.ready = True\n",
    "        \n",
    "        if not os.path.exists(self.final_folder):\n",
    "            os.makedirs(self.final_folder)\n",
    "        if not os.path.exists(self.final_stats_folder):\n",
    "            os.makedirs(self.final_stats_folder)\n",
    "    \n",
    "    \n",
    "    def check_zonal(self):\n",
    "        csv_files = []\n",
    "        for root, dirs, files in os.walk(self.cur_folder):\n",
    "            for f in files:\n",
    "                if f[-4:] == \".csv\" and not \"FINAL_STATS\" in root:\n",
    "                    csv_files.append(os.path.join(root, f))\n",
    "        self.csv_files = csv_files\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            cur_res = pd.read_csv(csv_file)\n",
    "            geom_file = os.path.basename(csv_file).replace(\".csv\",\"\").replace(\"_zonal\",\"\").replace(\"_BASE\",\"\").replace(\"_DHS\",\"\") + \".geojson\"\n",
    "            geom_file = os.path.join(self.final_folder, geom_file)\n",
    "            if os.path.exists(geom_file):\n",
    "                raw_data = gpd.read_file(geom_file)\n",
    "                pk_column = \"geohash\"\n",
    "                if os.path.basename(csv_file)[:3] == \"adm\":\n",
    "                    pk_column = f\"WB_ADM{os.path.basename(csv_file)[3:4]}_CO\"\n",
    "                if \"BASE\" in csv_file:\n",
    "                    orig_columns = list(cur_res.columns)\n",
    "                    orig_columns[-len(self.LC_cols):] = self.LC_cols\n",
    "                    cur_res.columns = orig_columns\n",
    "                if \"_DHS\" in csv_file:\n",
    "                    cur_res.rename(columns = self.dhs_column_defs, inplace=True)\n",
    "                cur_res['geom_key'] = raw_data[pk_column]\n",
    "                cur_res.to_csv(os.path.join(self.final_stats_folder, os.path.basename(csv_file)))\n",
    "        return(self.csv_files)\n",
    "            \n",
    "\n",
    "    def check_for_fishnets(self):\n",
    "        self.fishnets = False\n",
    "        for f in self.files:\n",
    "            if \"URBAN_\" in f:\n",
    "                self.fishnets = True\n",
    "                return(self.fishnets)\n",
    "        return(self.fishnets)\n",
    "        \n",
    "    def write_geom_data(self):\n",
    "        for f in self.files:\n",
    "            inD = gpd.read_file(f)\n",
    "            inD = inD.to_crs({'init':'epsg:4326'})\n",
    "            if not 'geohash' in inD.columns:\n",
    "                try:\n",
    "                    inD['geohash'] = inD['geometry'].apply(lambda x: geohash.encode(x.centroid.y, x.centroid.x))\n",
    "                except:\n",
    "                    raise(ValueError(f))\n",
    "            for col in self.bad_cols:\n",
    "                if col in inD.columns:\n",
    "                    inD.drop([col],axis=1,inplace=True)\n",
    "            inD.to_file(os.path.join(self.final_folder, os.path.basename(f).replace(\".shp\",\".geojson\")), driver=\"GeoJSON\")\n",
    "      \n",
    "    def zip_folder(self, folder, out_file):\n",
    "        # ziph is zipfile handle\n",
    "        zipf = zipfile.ZipFile(out_file, 'w', zipfile.ZIP_DEFLATED)\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file))\n",
    "                \n",
    "    def check_for_zip(self):\n",
    "        stats_files = os.listdir(self.final_stats_folder)\n",
    "        # list all geojson files in FINAL_GEOMS\n",
    "        self.ready = True\n",
    "        for g_file in os.listdir(self.final_folder):\n",
    "            stats_file_base = g_file.replace(\".geojson\", \"_zonal_BASE.csv\")\n",
    "            stats_file_dhs = g_file.replace(\".geojson\", \"_zonal_DHS.csv\")\n",
    "            if (not stats_file_base in stats_files) or (not stats_file_dhs in stats_files):                \n",
    "                self.ready = False\n",
    "        return(self.ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso3 = 'VNM'\n",
    "files = outputs[iso3]\n",
    "xx = covid_result(iso3, files, os.path.join(covid_folder, iso3), column_defs)\n",
    "xx.check_zonal()\n",
    "xx.check_for_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_zip_folder = \"/home/wb411133/data/Projects/CoVID_FINAL\"\n",
    "covid_folder = \"/home/wb411133/data/Projects/CoVID\"\n",
    "outputs = {}\n",
    "bad_files = []\n",
    "for folder in all_folders:\n",
    "    shps = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f[-4:] == \".shp\":\n",
    "                shps.append(os.path.join(root, f))\n",
    "            if f[:3] == \"ADM\":\n",
    "                bad_files.append(os.path.join(root, f))\n",
    "    outputs[os.path.basename(folder)] = shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VNM\n",
      "ARG\n",
      "PAK\n",
      "ZAF\n",
      "COL\n",
      "ZWE\n",
      "MNG\n",
      "SLE\n",
      "CPV\n",
      "KEN\n",
      "GHA\n",
      "AFG\n",
      "YEM\n",
      "ECU\n",
      "PRY\n",
      "MRT\n",
      "MDV\n",
      "KGZ\n",
      "HTI\n",
      "DJI\n",
      "KHM\n",
      "TJK\n",
      "GMB\n",
      "LKA\n",
      "SEN\n",
      "STP\n",
      "SLV\n",
      "VEN\n",
      "MLI\n",
      "RWA\n",
      "BOL\n",
      "TZA\n",
      "MAR\n",
      "IND\n",
      "IDN\n",
      "SDN\n",
      "AGO\n",
      "BEN\n",
      "BWA\n",
      "BWA is not ready\n",
      "BFA\n",
      "BDI\n",
      "CMR\n",
      "CAF\n",
      "TCD\n",
      "COM\n",
      "COG\n",
      "CIV\n",
      "COD\n",
      "SSD\n",
      "ERI\n",
      "ETH\n",
      "GAB\n",
      "GNB\n",
      "GIN\n",
      "LSO\n",
      "LBR\n",
      "MDG\n",
      "MWI\n",
      "MUS\n",
      "MOZ\n",
      "NAM\n",
      "NER\n",
      "NGA\n",
      "SYC\n",
      "SOM\n",
      "SWZ\n",
      "TGO\n",
      "UGA\n",
      "ZMB\n",
      "LCA\n",
      "PHL\n",
      "GTM\n",
      "BGD\n",
      "BRA\n",
      "BRA is not ready\n",
      "MEX\n",
      "MEX is not ready\n",
      "EGY\n",
      "EGY is not ready\n",
      "UKR\n",
      "UKR is not ready\n",
      "PER\n",
      "PER is not ready\n",
      "LAO\n",
      "PSE\n",
      "NPL\n",
      "PNG\n",
      "DZA\n",
      "BLR\n",
      "BTN\n",
      "BIH\n",
      "NIC\n",
      "FJI\n",
      "FJI is not ready\n",
      "GEO\n",
      "HND\n",
      "JOR\n",
      "MHL\n",
      "MDA\n",
      "MMR\n",
      "MKD\n",
      "PAN\n",
      "WSM\n",
      "SLB\n",
      "TUN\n",
      "TUR\n",
      "URY\n",
      "UZB\n",
      "ALB\n",
      "HRV\n",
      "IRN\n",
      "SRB\n",
      "TTO\n",
      "ATG\n",
      "CHN\n",
      "IRQ\n"
     ]
    }
   ],
   "source": [
    "def process_all(iso3, files, out_z_folder):\n",
    "    print(iso3)\n",
    "    final_geometry_zip = os.path.join(out_z_folder, \"%s_GEOMETRY.zip\" % iso3)\n",
    "    final_stats_zip = os.path.join(out_z_folder, \"%s_STATS.zip\" % iso3)\n",
    "    xx = covid_result(iso3, files, os.path.join(covid_folder, iso3), column_defs)\n",
    "    if not os.path.exists(final_geometry_zip) or not os.path.exists(final_stats_zip):\n",
    "        fishnets_exist = xx.check_for_fishnets()\n",
    "        if not fishnets_exist:\n",
    "            print(\"Creating fishnet for %s\" % iso3)\n",
    "            extent_file = os.path.join(covid_folder, iso3, \"urban_areas_hd.shp\")\n",
    "            prefix = \"HD_URBAN\"\n",
    "            out_folder = os.path.join(covid_folder, iso3, \"hd_urban_fishnets\")\n",
    "            if not os.path.exists(extent_file):\n",
    "                extent_file = os.path.join(covid_folder, iso3, \"urban_areas.shp\")\n",
    "                prefix = \"URBAN\"\n",
    "                out_folder = os.path.join(covid_folder, iso3, \"urban_fishnets\")\n",
    "            if os.path.exists(extent_file):\n",
    "                if not os.path.exists(out_folder):\n",
    "                    os.makedirs(out_folder)\n",
    "                cov.create_fishnet(extent_file, out_folder, prefix)\n",
    "            else:\n",
    "                print(\"ERROR with %s\" % iso3)\n",
    "        xx.write_geom_data()\n",
    "        xx.zip_folder(xx.final_folder, final_geometry_zip)            \n",
    "        res = xx.check_zonal()\n",
    "        if xx.check_for_zip():\n",
    "            xx.zip_folder(xx.final_stats_folder, final_stats_zip)\n",
    "        else:\n",
    "            print(\"%s is not ready\" % iso3)\n",
    "    return(xx)\n",
    "    \n",
    "all_bad = []\n",
    "for iso3, files in outputs.items():\n",
    "    res = process_all(iso3, files, out_zip_folder)\n",
    "    if not res.ready:\n",
    "        all_bad.append(res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'BWA'\n",
      "'BRA'\n",
      "'MEX'\n",
      "'EGY'\n",
      "'UKR'\n",
      "'PER'\n",
      "'FJI'\n"
     ]
    }
   ],
   "source": [
    "for x in all_bad:\n",
    "    print(\"'%s'\" % x.iso3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir(out_zip_folder):\n",
    "    if \"GEOMETRY\" in f:\n",
    "        print(f\"aws s3 cp {f} s3://covid-wb/data/{f} --profile covid\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso3 = 'IDN'\n",
    "files = outputs[iso3]\n",
    "\n",
    "final_geometry_zip = os.path.join(out_zip_folder, \"%s_GEOMETRY.zip\" % iso3)\n",
    "final_stats_zip = os.path.join(out_zip_folder, \"%s_STATS.zip\" % iso3)\n",
    "if not os.path.exists(final_geometry_zip) or not os.path.exists(final_stats_zip):\n",
    "    xx = covid_result(iso3, files, os.path.join(covid_folder, iso3), column_defs)\n",
    "    fishnets_exist = xx.check_for_fishnets()\n",
    "    if not fishnets_exist:\n",
    "        print(\"Creating fishnet for %s\" % iso3)\n",
    "        extent_file = os.path.join(covid_folder, iso3, \"urban_areas_hd.shp\")\n",
    "        prefix = \"HD_URBAN\"\n",
    "        out_folder = os.path.join(covid_folder, iso3, \"hd_urban_fishnets\")\n",
    "        if not os.path.exists(extent_file):\n",
    "            extent_file = os.path.join(covid_folder, iso3, \"urban_areas.shp\")\n",
    "            prefix = \"URBAN\"\n",
    "            out_folder = os.path.join(covid_folder, iso3, \"urban_fishnets\")\n",
    "        if os.path.exists(extent_file):\n",
    "            if not os.path.exists(out_folder):\n",
    "                os.makedirs(out_folder)\n",
    "            cov.create_fishnet(extent_file, out_folder, prefix)\n",
    "        else:\n",
    "            print(\"ERROR with %s\" % iso3)\n",
    "    xx.write_geom_data()\n",
    "    res = xx.check_zonal()\n",
    "    if len(res)/len(xx.files) >= 2:\n",
    "        xx.zip_folder(xx.final_folder, final_geometry_zip)\n",
    "        xx.zip_folder(xx.final_stats_folder, final_stats_zip)\n",
    "    else:\n",
    "        print(\"%s is not ready\" % iso3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xx.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geog)",
   "language": "python",
   "name": "geog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
