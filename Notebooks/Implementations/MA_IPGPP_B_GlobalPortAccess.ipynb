{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, importlib\n",
    "import rasterio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import GOSTnets as gn\n",
    "import skimage.graph as graph\n",
    "\n",
    "from rasterio.mask import mask\n",
    "from rasterio import features\n",
    "from shapely.geometry import box, Point, Polygon\n",
    "from scipy.ndimage import generic_filter\n",
    "from pandana.loaders import osm\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import infrasap.market_access as ma\n",
    "import infrasap.rasterMisc as rMisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_friction_file    = \"/home/public/Data/GLOBAL/INFRA/FRICTION_2015/2015_friction_surface_v1.geotiff\"\n",
    "global_friction_noOcean = \"/home/public/Data/GLOBAL/INFRA/FRICTION_2015/2015_friction_surface_v1_no_ocean_travel.tif\"\n",
    "ports_file = \"/home/wb411133/data/Global/INFRA/PORTS/major_ports.shp\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(global_friction_noOcean):# Burn the oceans in as a no travel zone\n",
    "    inG = rasterio.open(global_friction_file)\n",
    "    inG_data = inG.read()[0,:,:]\n",
    "    inG_data = inG_data * 1000\n",
    "    \n",
    "    ocean_file = \"/home/public/Data/GLOBAL/ADMIN/OCEAN/ne_10m_ocean.shp\"\n",
    "    cMeta = inG.meta.copy()\n",
    "\n",
    "    inO = gpd.read_file(ocean_file)\n",
    "    shapes = ((row.geometry,999999) for idx, row in inO.iterrows())\n",
    "    burned = features.rasterize(shapes=shapes, out_shape=(cMeta['height'], cMeta['width']), \n",
    "                                transform=cMeta['transform'], dtype=cMeta['dtype'])\n",
    "    inG_combo = inG_data + burned\n",
    "    out_file = \"/home/wb411133/temp/2015_friction_surface_v1_no_ocean_travel.tif\"\n",
    "    with rasterio.open(out_file, 'w', **cMeta) as out:\n",
    "        out.write_band(1, inG_combo)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inG = rasterio.open(global_friction_noOcean)\n",
    "inP = gpd.read_file(ports_file)\n",
    "\n",
    "inG_data = inG.read()[0,:,:]\n",
    "mcp = graph.MCP_Geometric(inG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach ISO3 codes and regions to ports\n",
    "global_boundaries =  \"/home/public/Data/GLOBAL/ADMIN/Admin0_Polys.shp\"\n",
    "inB = gpd.read_file(global_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inP = gpd.read_file(ports_file)\n",
    "if inP.crs != inB.crs:\n",
    "    inP = inP.to_crs(inB.crs)\n",
    "    \n",
    "inP['ISO3'] = ''\n",
    "inP['REGION'] = ''\n",
    "for idx, row in inP.iterrows():\n",
    "    sel_country = inB.loc[inB.intersects(row['geometry'])]\n",
    "    if sel_country.shape[0] > 0:\n",
    "        inP.loc[idx,'ISO3'] = sel_country['ISO3'].iloc[0]\n",
    "        inP.loc[idx,'REGION'] = sel_country['Region'].iloc[0]\n",
    "    else:\n",
    "        print(f\"{idx}: {row['Postal']}\")\n",
    "              \n",
    "inP = inP.to_crs({'init':'epsg:4326'})\n",
    "inP.to_file(ports_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "selP = inP#.loc[inP['REGION'] == 'South Asia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 19\n",
      "13:13:37\t1 of 1\n",
      "Processing 20\n",
      "13:26:37\t1 of 1\n",
      "Processing 23\n",
      "13:39:31\t1 of 1\n",
      "Processing 24\n",
      "13:51:56\t1 of 1\n",
      "Processing 41\n",
      "14:04:20\t1 of 1\n",
      "Processing 46\n",
      "14:17:02\t1 of 1\n",
      "Processing 47\n",
      "14:29:34\t1 of 1\n",
      "Processing 51\n",
      "14:42:15\t1 of 1\n",
      "Processing 63\n",
      "14:54:49\t1 of 1\n",
      "Processing 89\n",
      "15:07:40\t1 of 1\n",
      "Processing 122\n",
      "15:20:55\t1 of 1\n",
      "Processing 124\n",
      "15:33:36\t1 of 1\n",
      "Processing 132\n",
      "15:47:49\t1 of 1\n",
      "Processing 138\n",
      "16:00:20\t1 of 1\n",
      "Processing 152\n",
      "16:13:23\t1 of 1\n",
      "Processing 165\n",
      "16:25:43\t1 of 1\n",
      "Processing 166\n",
      "16:39:35\t1 of 1\n",
      "Processing 173\n",
      "16:53:34\t1 of 1\n",
      "Processing 175\n",
      "17:06:07\t1 of 1\n",
      "Processing 103\n",
      "17:19:51\t1 of 1\n",
      "Processing 102\n",
      "17:33:07\t1 of 1\n",
      "Processing 104\n",
      "17:46:11\t1 of 1\n",
      "Processing 105\n",
      "17:59:34\t1 of 1\n",
      "Processing 55\n",
      "18:12:48\t1 of 1\n",
      "Processing 62\n",
      "18:25:39\t1 of 1\n",
      "Processing 61\n",
      "18:38:27\t1 of 1\n",
      "Processing 67\n",
      "18:51:16\t1 of 1\n",
      "Processing 114\n",
      "19:03:52\t1 of 1\n",
      "Processing 45\n",
      "19:16:24\t1 of 1\n",
      "Processing 44\n",
      "19:28:54\t1 of 1\n",
      "Processing 127\n",
      "19:41:41\t1 of 1\n",
      "Processing 126\n",
      "19:55:00\t1 of 1\n",
      "Processing 119\n",
      "20:08:22\t1 of 1\n",
      "Processing 118\n",
      "20:20:57\t1 of 1\n",
      "Processing 52\n",
      "20:33:32\t1 of 1\n",
      "Processing 120\n",
      "20:46:05\t1 of 1\n",
      "Processing 10\n",
      "20:58:55\t1 of 1\n",
      "Processing 123\n",
      "21:11:37\t1 of 1\n",
      "Processing 36\n",
      "21:25:43\t1 of 1\n",
      "Processing 90\n",
      "21:38:43\t1 of 1\n",
      "Processing 37\n",
      "21:51:17\t1 of 1\n",
      "Processing 39\n",
      "22:04:05\t1 of 1\n",
      "Processing 38\n",
      "22:16:54\t1 of 1\n",
      "Processing 66\n",
      "22:29:46\t1 of 1\n",
      "Processing 125\n",
      "22:42:21\t1 of 1\n",
      "Processing 40\n",
      "22:55:57\t1 of 1\n",
      "Processing 31\n",
      "23:08:29\t1 of 1\n",
      "Processing 32\n",
      "23:21:42\t1 of 1\n",
      "Processing 34\n",
      "23:34:57\t1 of 1\n",
      "Processing 33\n",
      "23:48:21\t1 of 1\n",
      "Processing 35\n",
      "00:01:48\t1 of 1\n",
      "Processing 7\n",
      "00:15:15\t1 of 1\n",
      "Processing 6\n",
      "00:28:40\t1 of 1\n",
      "Processing 9\n",
      "00:42:09\t1 of 1\n",
      "Processing 5\n",
      "00:55:31\t1 of 1\n",
      "Processing 8\n",
      "01:09:04\t1 of 1\n",
      "Processing 168\n",
      "01:22:24\t1 of 1\n",
      "Processing 27\n",
      "01:35:40\t1 of 1\n",
      "Processing 26\n",
      "01:49:15\t1 of 1\n",
      "Processing 18\n",
      "02:02:24\t1 of 1\n",
      "Processing 16\n",
      "02:15:35\t1 of 1\n",
      "Processing 15\n",
      "02:28:47\t1 of 1\n",
      "Processing 14\n",
      "02:41:29\t1 of 1\n",
      "Processing 25\n",
      "02:55:06\t1 of 1\n",
      "Processing 17\n",
      "03:07:39\t1 of 1\n",
      "Processing 21\n",
      "03:21:08\t1 of 1\n",
      "Processing 22\n",
      "03:34:21\t1 of 1\n",
      "Processing 143\n",
      "03:47:26\t1 of 1\n",
      "Processing 100\n",
      "04:00:02\t1 of 1\n",
      "Processing 158\n",
      "04:12:43\t1 of 1\n",
      "Processing 65\n",
      "04:25:01\t1 of 1\n",
      "Processing 64\n",
      "04:37:27\t1 of 1\n",
      "Processing 146\n",
      "04:49:56\t1 of 1\n",
      "Processing 95\n",
      "05:02:24\t1 of 1\n",
      "Processing 96\n",
      "05:14:52\t1 of 1\n",
      "Processing 107\n",
      "05:27:20\t1 of 1\n",
      "Processing 106\n",
      "05:39:51\t1 of 1\n",
      "Processing 59\n",
      "05:52:23\t1 of 1\n",
      "Processing 60\n",
      "06:04:58\t1 of 1\n",
      "Processing 159\n",
      "06:17:33\t1 of 1\n",
      "Processing 3\n",
      "06:30:18\t1 of 1\n",
      "Processing 13\n",
      "06:43:03\t1 of 1\n",
      "Processing 2\n",
      "06:55:50\t1 of 1\n",
      "Processing 115\n",
      "07:08:33\t1 of 1\n",
      "Processing 56\n",
      "07:21:02\t1 of 1\n",
      "Processing 29\n",
      "07:33:26\t1 of 1\n",
      "Processing 30\n",
      "07:46:15\t1 of 1\n",
      "Processing 160\n",
      "07:59:01\t1 of 1\n",
      "Processing 4\n",
      "08:11:43\t1 of 1\n",
      "Processing 48\n",
      "08:24:25\t1 of 1\n",
      "Processing 113\n",
      "08:37:46\t1 of 1\n",
      "Processing 49\n",
      "08:50:25\t1 of 1\n",
      "Processing 154\n",
      "09:03:22\t1 of 1\n",
      "Processing 151\n",
      "09:15:50\t1 of 1\n",
      "Processing 1\n",
      "09:28:28\t1 of 1\n",
      "Processing 97\n",
      "09:42:08\t1 of 1\n",
      "Processing 162\n",
      "09:55:24\t1 of 1\n",
      "Processing 53\n",
      "10:09:00\t1 of 1\n",
      "Processing 163\n",
      "10:22:46\t1 of 1\n",
      "Processing 164\n",
      "10:36:41\t1 of 1\n",
      "Processing 150\n",
      "10:50:37\t1 of 1\n",
      "Processing 167\n",
      "11:03:11\t1 of 1\n",
      "Processing 153\n",
      "11:17:01\t1 of 1\n",
      "Processing 54\n",
      "11:29:34\t1 of 1\n",
      "Processing 110\n",
      "11:43:30\t1 of 1\n",
      "Processing 108\n",
      "11:56:14\t1 of 1\n",
      "Processing 139\n",
      "12:08:56\t1 of 1\n",
      "Processing 161\n",
      "12:22:09\t1 of 1\n",
      "Processing 109\n",
      "12:36:25\t1 of 1\n",
      "Processing 91\n",
      "12:48:47\t1 of 1\n",
      "Processing 93\n",
      "13:02:30\t1 of 1\n",
      "Processing 94\n",
      "13:16:51\t1 of 1\n",
      "Processing 156\n",
      "13:31:09\t1 of 1\n",
      "Processing 140\n",
      "13:45:31\t1 of 1\n",
      "Processing 142\n",
      "14:00:17\t1 of 1\n",
      "Processing 157\n",
      "14:14:47\t1 of 1\n",
      "Processing 92\n",
      "14:27:58\t1 of 1\n",
      "Processing 141\n",
      "14:40:23\t1 of 1\n",
      "Processing 58\n",
      "14:54:53\t1 of 1\n",
      "Processing 57\n",
      "15:07:28\t1 of 1\n",
      "Processing 147\n",
      "15:21:48\t1 of 1\n",
      "Processing 50\n",
      "15:34:36\t1 of 1\n",
      "Processing 43\n",
      "15:47:17\t1 of 1\n",
      "Processing 42\n",
      "15:59:42\t1 of 1\n",
      "Processing 149\n",
      "16:12:07\t1 of 1\n",
      "Processing 148\n",
      "16:24:46\t1 of 1\n",
      "Processing 98\n",
      "16:37:27\t1 of 1\n",
      "Processing 144\n",
      "16:49:51\t1 of 1\n",
      "Processing 145\n",
      "17:02:14\t1 of 1\n",
      "Processing 101\n",
      "17:14:38\t1 of 1\n",
      "Processing 111\n",
      "17:27:02\t1 of 1\n",
      "Processing 112\n",
      "17:41:31\t1 of 1\n",
      "Processing 84\n",
      "17:56:03\t1 of 1\n",
      "Processing 88\n",
      "18:08:38\t1 of 1\n",
      "Processing 28\n",
      "18:21:13\t1 of 1\n",
      "Processing 174\n",
      "18:34:43\t1 of 1\n",
      "Processing 171\n",
      "18:48:27\t1 of 1\n",
      "Processing 170\n",
      "19:02:16\t1 of 1\n",
      "Processing 169\n",
      "19:16:35\t1 of 1\n",
      "Processing 172\n",
      "19:30:03\t1 of 1\n",
      "Processing 87\n",
      "19:43:17\t1 of 1\n",
      "Processing 86\n",
      "19:55:42\t1 of 1\n",
      "Processing 85\n",
      "20:08:05\t1 of 1\n",
      "Processing 131\n",
      "20:20:30\t1 of 1\n",
      "Processing 133\n",
      "20:32:53\t1 of 1\n",
      "Processing 135\n",
      "20:45:16\t1 of 1\n",
      "Processing 128\n",
      "20:57:38\t1 of 1\n",
      "Processing 137\n",
      "21:10:02\t1 of 1\n",
      "Processing 129\n",
      "21:22:25\t1 of 1\n",
      "Processing 136\n",
      "21:34:47\t1 of 1\n",
      "Processing 134\n",
      "21:47:10\t1 of 1\n",
      "Processing 130\n",
      "21:59:31\t1 of 1\n",
      "Processing 121\n",
      "22:11:53\t1 of 1\n"
     ]
    }
   ],
   "source": [
    "travel_time_thresholds = [((24*60) * x) for x in [0.25,0.5,1,2]]\n",
    "out_folder = os.path.join(os.path.dirname(ports_file), \"TRAVEL_TIMES\")\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "port_files = []\n",
    "for idx, row in selP.iterrows():\n",
    "    name = row['OBJECTID']    \n",
    "    out_file = os.path.join(out_folder, \"PORT_ISOCHRONES_NO_OCEAN_%s.shp\" % name)\n",
    "    port_files.append(out_file)\n",
    "    if not os.path.exists(out_file):\n",
    "        print(\"Processing %s\" % name)\n",
    "        current_p = pd.DataFrame(selP.loc[idx,]).transpose()\n",
    "        travel_times = ma.generate_feature_vectors(inG, mcp, current_p, travel_time_thresholds)\n",
    "        travel_times.to_file(out_file)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del final\n",
    "except:\n",
    "    pass\n",
    "for p in port_files:\n",
    "    current_p = gpd.read_file(p)\n",
    "    current_p['PORT'] = p.split(\"_\")[-1].replace(\".shp\",\"\")\n",
    "    try:\n",
    "        final = final.append(current_p)\n",
    "    except:\n",
    "        final = current_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_file(os.path.join(out_folder, \"COMBO_all_ports.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wb411133/data/Global/INFRA/PORTS/TRAVEL_TIMES'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zonal Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "inShape = os.path.join(out_folder, \"COMBO_all_ports.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geog)",
   "language": "python",
   "name": "geog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
